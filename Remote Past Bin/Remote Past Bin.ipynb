{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51ad93-cfaf-4005-9390-45f67994dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sklearn\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193dcede-d088-4cbd-9cb7-839195a28361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training data \n",
    "#allData = pd.read_csv(\"remove_past_bin.txt\", delimiter=\"\\t\", quoting=csv.QUOTE_NONE, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d8f76-2fe4-427a-a165-3725db885fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing and adds speaker column\n",
    "speakers = []\n",
    "for i in range(len(allData)):\n",
    "    if (':' in allData.iloc[i, 0]):\n",
    "        index = allData.iloc[i, 0].index(':')\n",
    "        speakers.append((allData.iloc[i, 0])[:index+1])\n",
    "        allData.iloc[i, 0] = re.sub(\"[a-zA-Z]:\\s+\", \"\", allData.iloc[i, 0]) \n",
    "    else:\n",
    "        speakers.append('F:')\n",
    "    allData.iloc[i, 0] = re.sub(\"[a-zA-Z]:\\s+\", \"\", allData.iloc[i, 0])\n",
    "allData.insert (0, \"speaker\", speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843924d-8fea-445d-abe5-c30fbaa19a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "# Creates a Sentence object\n",
    "# text = text of Sentence\n",
    "# rp_bin = which occurence of been or bin is being looked at in the sentence\n",
    "  # eg. if the variable be is set to 2, the model will observe whether the second noun/verb clause contains an instance of remote past bin\n",
    "# num = the index of the Sentence in the original csv\n",
    "    remoteBin = 0\n",
    "    r1 = 0; r2 = 0;\n",
    "    def __init__(self, text, rp, num, true):\n",
    "        self.text = text\n",
    "        self.num = num\n",
    "        self.rp = rp\n",
    "        self.true = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ff4a8-4744-4886-acf2-8b25a294a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preproccesses training text for linguistic analysis\n",
    "\n",
    "lines = []\n",
    "\n",
    "with open(\"remote_past_bin.txt\", \"r\", encoding=\"utf-8\") as tsv_file: #these files are tab separated but you can easily change this to CSV\n",
    "    tsv_reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "    header = next(tsv_reader)\n",
    "    for row in tsv_reader:\n",
    "        row = row[:1]\n",
    "        row[0] = re.sub(\"[a-zA-Z]:\\s+\", \"\", row[0]) #removes the interviewer tag\n",
    "        row[0] = re.sub(\"\\s{2,}\", \" \", row[0]) #removes excessive spaces\n",
    "        row[0] = re.sub(\"’|‘\", \"'\", row[0]) #fixes apostrophes\n",
    "        row[0] = re.sub(\"—\", \"--\", row[0]) #m-dash was causing formatting issues, changed it to two dashes\n",
    "        row[0] = re.sub(\"“\", '\"', row[0]) #fixes quotation marks    \n",
    "        lines.append(row[0])\n",
    "         \n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27faa40b-f4d1-4b8e-b9e6-b3284273d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of Sentence objects with at least one 'been' or 'bin'\n",
    "\n",
    "sen = []\n",
    "for line in range(len(lines)):\n",
    "        rp = 1\n",
    "        numBin = 0\n",
    "        parsed = nlp(lines[line])\n",
    "        for i, word in enumerate(parsed):\n",
    "            if (word.text.lower() == \"been\" or word.text.lower() == \"bin\"):\n",
    "                numBin += 1\n",
    "        if (numBin >= 1):\n",
    "            sen.append(Sentence(lines[line], rp, line))\n",
    "            while (numBin > 1):\n",
    "                rp += 1\n",
    "                sen.append(Sentence(lines[line], rp, line))\n",
    "                numBin -= 1\n",
    "for Sentence in range(len(sen)):\n",
    "    sen[Sentence].text = (sen[Sentence].text).replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f6ab5-6461-417b-87d7-844dfcdab8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags the Sentence objects with each rule\n",
    "\n",
    "index = -1\n",
    "senNum = 1\n",
    "numBin = 0\n",
    "binIndices = []\n",
    "\n",
    "for Sentence in sen:\n",
    "    index += 1 \n",
    "    numBin = 0\n",
    "    if (index > 0 and (sen[index].text == sen[index-1].text) and (sen[index].num == sen[index-1].num)):\n",
    "        senNum += 1\n",
    "    else:\n",
    "        senNum = 1\n",
    "    parsed = nlp(Sentence.text)\n",
    "    for i, word in enumerate(parsed):\n",
    "        if (i >= 0 and (word.text.lower() in ('bin', 'been')) and Sentence.remoteBin != 1):\n",
    "            numBin += 1\n",
    "            if (numBin == senNum):\n",
    "                w.append(word.pos_)\n",
    "                binIndices.append(i)\n",
    "                binChildren = list(word.children)\n",
    "                if(word.head == word):\n",
    "                    binSibling = []\n",
    "                else:\n",
    "                    binSibling = list(word.head.children)\n",
    "                binDep = word.dep_\n",
    "                binPOS = word.pos_\n",
    "                binIndex = i\n",
    "                num = 1\n",
    "                next = None\n",
    "                prev = None\n",
    "                if (prev.pos_ == 'NOUN' or prev.pos_ == 'PRON' or prev.pos_ == 'PROPN') and (next.pos_ == 'VERB' or next.pos_ == 'AUX')\n",
    "                    r1 = 1\n",
    "#                if (Sentence.r2 != 1):\n",
    "#                    Sentence.r2 = 0\n",
    "                if (Sentence.r1 == 1):# and Sentence.r2 != 1):\n",
    "                    Sentence.remoteBin = 1\n",
    "                else:\n",
    "                    Sentence.remoteBin = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d9876-9b21-4edc-94fe-73ff30781ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidation bin values of duplicated sentences\n",
    "# e.g. if any have disagreement, assign all bin values to 1, else keep them as 0\n",
    "\n",
    "multBininSentence = []\n",
    "\n",
    "for i in range(len(sen)-1):\n",
    "    if (i < len(sen)-1):\n",
    "        j = i+1 \n",
    "        if (sen[i].text != sen[j].text):\n",
    "            if (sen[i].rp == 1):\n",
    "                multBininSentence.append(True)\n",
    "            else:\n",
    "                multBininSentence.append(False)\n",
    "        while (sen[i].text == sen[j].text):\n",
    "            if (sen[i].rp == 1 or sen[j].rp == 1):\n",
    "                multBininSentence.append(True)\n",
    "            else:\n",
    "                multBininSentence.append(False)\n",
    "            if (sen[j].rp == 1):\n",
    "                sen[i].rp == sen[j].rp\n",
    "            if (sen[i].rp == 1):\n",
    "                sen[j].rp == sen[i].rp\n",
    "            if (j < len(sen)-1):\n",
    "                j +=1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "if len(multBininSentence) != len(sen):\n",
    "    if (sen[-1].rp == 1):\n",
    "        multBininSentence.append(True)\n",
    "    else:\n",
    "        multBininSentence.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65e981-57d7-4fee-be0d-73a3e49eebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goes back to the original data and annotates each sentences with remote past bin or not\n",
    "\n",
    "remoteBin = []\n",
    "for i in range(len(allData)):\n",
    "    m = 0\n",
    "    for j in range(len(sen)):\n",
    "        if i == sen[j].num:\n",
    "            if (m != 1):\n",
    "                m = sen[j].rp\n",
    "            if (m == 1 and (\"%RPB\" not in allData.iloc[i, allData.columns.get_loc('Speaker')])):\n",
    "                allData.loc[i, 'Speaker'] = allData.iloc[i, allData.columns.get_loc('Speaker')] + \" %RPB\"\n",
    "    remoteBin.append(m)\n",
    "allData['remotePastBin'] = remoteBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0831e-0801-4a9d-a495-7e66b75b39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "\n",
    "predictions = allData['remotePastBin']\n",
    "y = allData['remotePastBIN']\n",
    "target_names = ['remotePast', 'none']\n",
    "print(classification_report(y, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984721d-afd0-4599-b382-bf29b0e2f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pastBin.txt', 'w+', newline='') as file:\n",
    "   allData.to_csv('pastBin.txt', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
